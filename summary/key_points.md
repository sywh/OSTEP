# 第4章 抽象：进程
## 要点
- 进程/机器状态/进程API/**程序如何转化为进程**/进程状态/进程数据结构/进程列表/进程控制块
- 虚拟化CPU/时分共享/空分共享/机制和策略/CPU利用率
## 知识点
- 进程：操作系统为正在运行的程序提供的抽象，就是所谓的进程
- 机器状态：指程序在运行时可以读取或更新的内容，包括进程可以访问的内存（称为地址空间），寄存器（包括特殊寄存器，如程序计数器、栈指针和帧指针），持久存储设备（包括当前打开的文件列表）
- 进程API：包括创建/销毁/等待/暂停/恢复/状态等
- 进程状态：运行/就绪/阻塞/僵尸
- CPU利用率：通过保持CPU繁忙可提高CPU利用率，如在进程发出I/O时进行上下文切换，运行其他进程
# 第5章 插叙：进程API
## 要点
- fork()/exec()/wait()
- 进程描述符(PID)/shell重定向和管道
## 知识点
- 进程API
  - fork(): 创建子进程，子进程和父进程都从fork()系统调用处返回
  - exec()：让子进程执行与父进程不同的程序
  - wait(): 等待进程执行完毕，如父进程执行wait()，延迟自己的执行，直到子进程执行完毕
- PID: PID是进程的标识符，如果要操作某个进程，就需要通过PID来指明
# 第6章 机制：受限直接运行
## 要点
- 受限直接执行/进程列表/受限操作
- 用户模式/内核模式/陷入内核/从陷阱返回/陷阱表/系统调用/内核栈/进程结构
- 协作调度系统/非协作调度系统/时钟中断
- 上下文切换/重启
## 知识点
- 受限操作：向磁盘发出I/O请求，获得更多系统资源（如CPU或内存），访问文件系统
- 用户模式：一种**处理器模式**，在用户模式下运行时，进程不能发出I/O请求，这样做会导致处理器引发异常，操作系统可能会终止进程
- 内核模式：操作系统（或内核）就以这种模式运行，可以执行特权操作，如发出I/O请求和执行所有类型的受限指令
- 系统调用：允许内核小心地向用户程序暴露某些关键功能。要执行系统调用，程序必须执行特殊的陷阱(trap)指令。该指令同时跳入内核并将特权级别提升至内核模式
- 陷阱表：内核通过在启动时设置陷阱表，来告诉硬件在发生某些异常事件时要运行哪些代码。操作系统通常通过某种特殊的指令，通知硬件这些陷阱处理程序的位置。一旦硬件被通知，它就会记住这些处理程序的位置，直到下一次重新启动机器，并且硬件知道在发生系统调用和其它异常事件时要做什么（即跳转到哪段代码）
- 内核栈：内核栈便于操作系统发出从陷阱返回指令时，能够正确返回用户程序。每个进程都有一个内核栈，在进入内核和离开内核时，寄存器（包括通用寄存器和程序计数器）分别被保存和恢复
- 协作调度系统：OS通过等待系统调用，或某种非法操作发生，从而重新获得CPU的控制权
- 非协作调度系统：产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序会运行。此时，操作系统重新获得CPU控制权
# 第7章 进程调度：介绍
## 要点
- 工作负载/工作负载假设/（非）抢占式调度程序/IO负载
- 调度指标：周转时间/响应时间/性能和公平
- 调度策略：先进先出(FIFO)/最短任务优先(SJF)/最短完成时间优先(STCF)/轮转(RR)
- 护航效应/摊销/重叠
## 知识点
- 工作负载：运行中的进程
- RR:
  - 时间片长度对于RR至关重要。越短，RR在响应时间上的表现越好，但时间片太短，上下文切换的成本将影响整体性能。系统设计者需要权衡时间片的长度，使其足够长，以便摊销上下文切换成本，而又不会使系统不及时响应
  - 时间片长度必须是时钟中断周期的倍数
  - 如果周转时间是我们的指标，那么RR确实是最糟糕的策略之一
# 第8章 调度：多级反馈队列
## 要点
- 多级反馈队列/用历史经验预测未来/队列/优先级/不同队列时间片长度不同
- 工作负载类型/饥饿问题/愚弄调度程序/一个程序可能在不同时间表现不同
- 巫毒常量/用户建议
## 知识点
- 工作负载类型：既有运行时间很短、频繁放弃CPU的**交互型工作**，也有需要很多CPU时间、响应时间却不重要的长时间**计算密集型工作**。CPU密集型工作一般都在最低优先级队列执行
# 第9章 调度：比例份额
## 要点
- 彩票调度/彩票数/随机性/彩票货币/彩票转让/彩票通胀/不公平指标U
- 步长调度/步长/行程值/调度周期
## 知识点
- 随机性的优点
  - 随机方法尝尝可以避免奇怪的边角情况，避免最差情况
  - 随机方法很轻量，几乎不需要记录任何状态
  - 随机方法很快，对运行速度要求高的场景非常适用
- 不公平指标U：将两个工作完成时间相除。当工作执行时间很短时，平均不公平度非常糟糕。只有当工作执行非常多的时间片时，彩票调度算法才能得到期望的结果
- 步长：每个工作都有自己的步长，这个值与票数值成反比，通过用一个大数分别除以每个工作的票数来获得每个进程的步长
# 第10章 多处理器调度
# 第13章 抽象：地址空间
## 要点
- 虚拟化内存/地址空间/隔离原则
- 虚拟内存的目标：透明/效率/保护
## 知识点
- 虚拟化内存：操作系统在单一的物理内存上，为多个运行的进程构建一个私有的、可能很大的地址空间
- 地址空间：物理内存的抽象，是运行的程序看到的系统中的内存。一个进程的地址空间包含运行的程序的所有状态，包括程序的代码，栈（保存当前的函数调用信息、分配空间给局部变量、传递参数和函数返回值）和堆（管理动态分配的、用户管理的内存）
# 第14章 插叙：内存操作API
## 要点
- 内存类型/栈内存/堆内存 
- malloc()/free()/NULL/强制类型转换/内存分配库/自动内存管理/垃圾收集器
- sizeof()/编译时操作符/strlen()
- 常见错误：忘记分配内存/没有分配足够的内存（**缓冲区溢出**）/忘记初始化分配的内存/忘记释放内存（**内存泄露**）/在用完之前释放内存（**悬挂指针**）/反复释放内存/错误地调用free()
- 两级内存管理/操作系统执行的内存管理/进程内存管理
- 内存debug工具：purify/valgrind
## 知识点
- 栈内存：申请和释放操作是编译器来隐式管理的。当你进入函数时，编译器在栈上开辟空间；当你从该函数退出时，编译器释放内存
- 堆内存：申请和释放操作都由程序员显式地完成。如果你希望某些信息存在于函数调用之外，建议不要将他们放在栈上。就是这种对长期内存的需求，所以我们才需要堆内存
- NULL：C中的NULL实际上并不是什么特别的东西，只是一个值为0的宏
- 编译时操作符：如sizeof()，大小在编译时就知道，因此被替换成一个数。sizeof()被认为是一个操作符，而不是一个函数调用（函数调用在运行时发生）
- 强制类型转换：针对malloc()，强制类型转换实际上并没干什么事，只是告诉编译器和其他可能正在读你的代码的程序员：“是的，我知道我在做什么”
- 自动内存管理：当你调用类似malloc()的机制来分配内存时，你永远不需要调用某些东西来释放空间。实际上，垃圾收集器会运行，找出你不再引用的内存，替你释放它。但是，如果你仍然拥有对某块内存的引用，那么垃圾收集器就不会释放它。因此即便在较现代的语言中，内存泄露仍然是一个问题
- 两级内存管理：系统中实际存在两级内存管理。第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出时将其回收。第二级管理在每个进程中，例如在调用malloc()和free()时，在堆内管理
# 第15章 机制：地址转换
## 要点
- 基于硬件的地址转换/虚拟地址/物理地址/介入
- 基址加界限机制（动态重定位）/基址寄存器/界限寄存器/静态重定位
- 内存管理单元(Memory Management Unit, MMU)/空闲列表
- 处理器状态字/触发异常/异常处理程序
- 内部碎片
## 知识点
- 基于硬件的地址转换：在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中实际的位置
- 基址加界限机制：基址寄存器将虚拟地址转换为物理地址，界限寄存器确保这个地址在进程地址空间的范围内。基址加界限机制让我们能够将地址空间放在物理内存的任何位置，同时又能确保进程只能访问自己的地址空间
- 内存管理单元：CPU中负责地址转换的部分统称为内存管理单元
- 空闲列表：操作系统必须记录哪些空闲内存没有使用，以便能够为进程分配内存。空闲列表是一个列表，记录当前没有使用的物理内存的范围
- **内部碎片**：动态重定位内存使用效率低下，其使用的是连续的内存区域，由于进程的栈区和堆区并不很大，导致这块内存区域中大量的空间被浪费（设想一个32位的地址空间，通常的程序只会使用几兆的内存，但需要整个地址空间都放在内存中）。这种浪费通常称为内部碎片，指的是已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费
# 第16章 分段
## 要点
- 分段/逻辑段/稀疏地址空间/段错误
- 段寄存器/显示方式/隐式方式/段的增长方向/代码段共享/保护位
- 外部碎片/紧凑物理内存/内存密集型/空闲列表管理算法
## 知识点
- 分段：在MMU中引入不止一个基址和界限寄存器对，而是给地址空间内的每个逻辑段一对
- 逻辑段：地址空间里的一个连续的区域，在典型的地址空间里有3个逻辑不同的段：代码、栈和堆
- 稀疏地址空间：包含大量未使用的地址空间，只有已用的内存才在物理内存中分配空间，因此可以容纳巨大的地址空间
- 段错误：指的是在支持分段的机器上发生了非法的内存访问。有趣的是，即使在不支持分段的机器上这个术语依然保留
- 段寄存器：硬件在地址转换时使用段寄存器，不同的位分别表示地址引用了哪个段，以及段内的偏移量。我理解就是包含3个基址+界限寄存器的内容，用虚拟地址来选择具体的段
- **外部碎片**：每个进程都有一些段，每个段的大小也可能不同，因此，物理内存很快充满了许多空闲空间的小洞，因而很难分配给新的段，或扩大已有的段，这种问题被称为外部碎片
- 紧凑物理内存：重新安排原有的段。例如，操作系统先终止运行的进程，将它们的数据复制到连续的内存区域中去，改变它们的段寄存器中的值，指向新的物理地址，从而得到了足够大的连续空闲空间。但是，内存紧凑成本很高，因为**拷贝段是内存密集型的，一般会占用大量的处理器时间**
- 分段的优缺点：
  - 通过避免地址空间的逻辑段之间的大量潜在的内存浪费，分段能更好地支持稀疏地址空间；
  - 分段很快，因为分段要求的算法很容易，很适合硬件完成，地址转换的开销极小；
  - 分段还有一个附加的好处：代码共享。如果代码放在独立的段中，这样的段就可能被多个运行的程序共享；
  - 由于段的大小不同，空闲内存被割裂成各种奇怪的大小，因此满足内存分配请求可能会很难，即外部碎片。用户可以尝试采用空闲列表管理算法，或定期紧凑内存，但无法完全避免
  - 分段还是不足以支持更一般化的稀疏地址空间。例如，如果有一个很大但是稀疏的堆，都在一个逻辑段中，整个堆仍然必须完整地加载到内存中
# 第17章 空闲空间管理
## 要点
- 外部碎片/用户级内存分配库/内存分配程序
- 分割与合并/头块/嵌入空闲列表/让堆增长
- 最优匹配/最差匹配/首次匹配/下次匹配
- 分离空闲列表/厚块分配程序/伙伴系统
## 知识点
- 外部碎片：如果要管理的空闲空间由大小不同的单元构成，管理就变得困难（而且有趣）。这种情况出现在用户级的内存分配库(如malloc()和free())，或者操作系统用分段的方式实现虚拟内存。在这两种情况下，出现了外部碎片的问题
- 分割与合并：如果请求的空间大小小于某块空闲块，分配程序通常会进行分割；分配程序会在释放一块内存时合并可用空间。想法很简单：在归还一块空闲内存时，仔细查看要归还的内存块的地址以及邻近的空闲空间块
- 头块：内存分配程序会在头块中保留一些额外信息，如分配空间的大小和一个幻数。头块在内存中，通常就在返回的内存块之前
- 嵌入空闲列表：在空闲内存本身中建立空闲空间列表
# 第18章 分页：介绍
## 要点
- 分页/页/页帧/页表
- 线性页表/有效位/保护位/存在位/脏位/参考位/页表项
- 页表基址寄存器
## 知识点
- 分页:将空间分割成固定长度的分片，在虚拟内存中，我们称这种思想为分页
- 页和页帧:虚拟地址空间中固定大小的单元称之为页；物理内存中定长槽块的阵列，叫做页帧。即页对应虚拟内存，页帧对应物理内存
- 页表：为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表。页表存储虚拟-物理地址转换，从而让系统知道地址空间的每个页实际驻留在物理内存中的哪个位置
- 有效位：有效位存储在页表项(PTE)中，对于支持稀疏地址空间至关重要。通过简单地将地址空间中所有未使用的页面标记为无效，我们不再需要为这些页面分配物理帧，从而节省大量内存
- 页表项：通过虚拟页号(VPN)检索线性页表，可以查找到页表项，页表项包括物理帧号(PFN)，以及许多不同的位
- 页表基址寄存器：包含页表的起始位置的物理地址，页表存储在内存中
- 分页的优缺点
  - 分页不会导致外部碎片，因为分页（按设计）将内存划分为固定大小的单元
  - 分页非常灵活，支持稀疏虚拟地址空间
  - 分页可能会导致较慢的机器（有许多额外的内存访问来访问页表）
  - 分页可能会导致内存浪费（内存被页表塞满而不是有用的应用程序数据）
# 第19章 分页：快速地址转换（TLB）
## 要点
- 地址转换缓存(TLB)/缓存/空间局部性/时间局部性
- 硬件管理TLB/软件管理TLB/复杂指令集计算(CISC)/精简指令集计算(RISC)
- 地址空间标识符(ASID)/缓存替换/随机访问存储器(RAM)/超出TLB覆盖范围
## 知识点
- TLB：
  - 频繁发生的虚拟到物理地址转换的硬件缓存(cache)，因此，更好的名称应该是地址转换缓存
  - TLB在处理器核心附近，设计的访问速度很快
  - 相对于大多数CPU指令，内存访问开销很大，TLB未命中导致更多的内存访问。因此，我们希望尽可能避免TLB未命中
  - VPN和PFN同时存在于TLB中，因为一条地址映射可能出现在任意位置。硬件会并行查找TLB，找到期望的转换映射
- 缓存：
  - 缓存是计算机系统中最基本的性能改进技术之一，一次又一次地用于让“常见的情况更快”
  - 硬件缓存背后的思想是利用指令和数据引用的局部性。通常有两种局部性：时间局部性和空间局部性
  - 如果想要快速地缓存，它就必须小，因为光速和其它物理限制会起作用。大的缓存注定慢，因此无法实现目的
- **空间局部性**：当程序访问内存地址x时，可能很快会访问邻近x的内存的内存。想想遍历某种数组，访问一个接一个的元素。即便是程序首次访问数组，得益于空间局部性，TLB还是能提高性能
- **时间局部性**：最近访问过的指令或数据项可能很快会再次访问。想想循环中的循环变量或指令，它们被多次重复访问。由于时间局部性，即在短时间内对内存项再次引用，所以TLB的命中率会很高
- 软件管理TLB：
  - 优势是灵活性，操作系统可以用任意数据结构来实现页表，不需要改变硬件
  - 从TLB未命中的陷阱返回后，硬件必须从导致陷阱的指令继续执行。因此，根据陷阱或异常的原因，系统在陷入内核时必须保存不同的程序计数器，以便将来能够正确地继续执行
  - 在运行TLB未命中处理代码时，操作系统需要格外小心避免引起TLB未命中的无限递归
- ASID：地址空间标识符，可以把ASID看作是进程标识符PID，但通常比PID位数少，PID一般是32位，ASID一般是8位
- RAM：随机存取存储器暗示你访问RAM的任意部分都一样快，但RAM不总是RAM，有时候随机访问地址空间，尤其是TLB没有缓存的页，可能导致严重的性能损失
- 超出TLB覆盖范围：如果一个程序短时间内访问的页数超过了TLB中的页数，就会产生大量的TLB未命中，运行速度就会变慢。解决这个问题的一种方案是支持更大的页
# 第20章 分页：较小的表
## 要点
- 较小的页/较大的页/多种页大小
- 分页和分段/多级页表/页目录/页目录项
- 时空折中/最小复杂性系统
## 知识点
- 较小的页：线性页表太大，在典型系统上占用太多内存
- 较大的页：造成每页内的浪费，导致内部碎片
- 多种页大小：主要原因不是为了节省页表空间，而是为了减少TLB的压力，让程序能够访问更多的地址空间而不会遭受太多的TLB未命中之苦（大型页只占用一个TLB项）
- 分页和分段：
  - 分页中大部分页表都没有使用，充满了无效的项，造成内存浪费
  - 分页和分段中不是为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个。其中，基址寄存器保存逻辑段页表的物理地址，界限寄存器用于指示页表的结尾
  - 优点：与线性页表相比，杂合方法实现了显著的内存节省。栈和堆之间未分配的页不再占用页表中的空间
  - 缺点：
    - 仍然要求使用分段，而分段并不像我们需要的那样灵活。如果有一个大而稀疏的堆，仍然可能导致大量的页表浪费
    - 导致外部碎片再次出现：尽管大部分内存是以页面大小单位管理的，但页表现在可以是任意大小（PTE的倍数）。因此，在内存中为它们寻找自由空间更为复杂
- 多级页表：
  - 目标是去掉页表中的所有无效区域，而不是将它们全部保留在内存中
  - 首先，将页表分为页大小的单元。然后，如果整页的页表项(PTE)无效，就完全不分配该页的页表
  - 为了追踪页表的页是否有效（以及如果有效，它在内存中的位置），使用了名为页目录的新结构
  - 优点：多级页表分配的页表空间，与你正在使用的地址空间内存量成正比。因此它通常很紧凑，并且支持稀疏的地址空间
  - 缺点：
    - 多级页表是有成本的。在TLB未命中时，需要从内存加载两次，才能从页表中获取正确的地址转换信息
    - 页表查找更加复杂
- 页目录：页目录可以告诉你页表的页在哪里，或者页表的整个页不包含有效页
# 第21章 超越物理内存：机制
## 要点
- 巨大的地址空间/交换空间
- 存在位/页错误/页错误处理程序/页交换策略
- 高水位线/低水位线/交换守护进程
## 知识点
- 巨大的地址空间：要求操作系统支持比物理内存更大的地址空间，不比担心程序的数据结构是否有足够空间存储
- 交换空间：在硬盘上开辟一部分空间用于物理页的移入和移出，这样的空间称为交换空间。交换空间的大小是非常重要的，它决定了系统在某一时刻能够使用的最大内存页数
- 存在位：页表项PTE中存在位表示该页是否存在于物理内存中
- 页错误：即页未命中，指程序访问的虚拟空间页被操作系统交换到了硬盘上
- 页错误处理程序：
  - 操作系统可以用PTE中的某些位来存储硬盘地址（来寻找交换到磁盘上的页的位置），这些位通常用来存储像页的PFN这样的数据
  - 当操作系统接收到页错误时，它会在PTE中查找地址，并将请求发送到硬盘，将页读取到内存中
  - 当硬盘I/O完成时，操作系统会更新页表，将此页标记为存在，更新PTE的PFN字段以记录新获取页的内存位置，并重试指令
- 交换守护进程：当操作系统发现有少于LW个页可用时，后台负责释放内存的线程会开始运行，直到有HW个可用的物理页，这个后台线程称为交换守护进程
# 第22章 超越物理内存：策略
## 要点
- 替换策略/缓存管理/平均内存访问时间
- 最优替换策略/FIFO/随机/LRU/近似LRU
- 冷启动未命中/容量未命中/冲突未命中
- Belady的异常/栈特性/局部性原则/无状态策略
- 无局部性工作负载/80-20工作负载/循环工作负载
- 使用位/脏位/预取/抖动/准入控制/内存过载
## 知识点
- 替换策略：如果拥有大量空闲内存，页错误发生时，在空闲页列表中找到空闲页，将它分配给不在内存中的页。当内存不够时，由于内存压力迫使操作系统换出一些页，为常用的页腾出空间。确定要踢出哪些页封装在操作系统的替换策略中
- 缓存管理：由于内存只包含系统中所有页的子集，因此可以将其视为系统中虚拟内存页的缓存。因此，在为这个缓存选择替换策略时，我们的目标是让缓存未命中最少，即使得从磁盘获取页的次数最少
- 最优替换策略：替换内存中在最远将来才会被访问到的页，可以达到缓存未命中率最低。缓存中所有其它页都比最远将来才会访问的页重要。**知道最优策略可以方便进行对比**，知道你的策略有多大的改进空间，也用于决定当策略已经非常接近最优策略时，停止做无谓的优化
- 冷启动未命中：即强制未命中，是因为缓存一开始是空的，导致的未命中
- 容量未命中：由于缓存的空间不足而不得不踢出一个项目以将新项目引入缓存，就发生了容量未命中
- FIFO：优点是实现简单，缺点是无法确定页的重要性，且没有栈特性，可能会发生Belady异常
- Belady异常：当缓存变大时，缓存命中率一般是会提高的，Belady异常则相反，出现在FIFO和随机策略等没有栈特性的策略中
- 栈特性：大小为N+1的缓存自然包括大小为N的缓存的内容
- 随机策略：实现起来很简单，但它在挑选替换哪个页时不够智能
- LRU：为了提高后续的命中率，我们再次通过历史的访问情况作为参考。该策略基于局部性原则：程序倾向于频繁地访问某些代码（例如循环）和数据结构（例如循环访问的数组）。LRU是一种**有状态**的策略。
  - 优点：基于局部性原则，一般情况下命中率较高
  - 缺点：在每次页访问时，都必须更新一些数据，从而将该页移到列表的前面（即MRU侧）。为了记录哪些页是最少和最近被使用，系统必须对每次内存引用做一些记录工作。如果不小心，这样的记录反而会极大地影响性能
- 工作负载
  - 无局部性工作负载：每次引用都是访问一个随机页
  - 80-20工作负载：表现出局部性，80%的引用是访问20%的页（热门页），剩下的20%是对剩余80%的页（冷门页）访问。LRU更好，因为它更可能保持热门页。由于这些页面过去经常被提及，它们很可能在不久的将来再次被提及
  - 循环工作负载：依次访问页。随机策略更好，能避免非零命中率。可以看出随机策略有一些不错的属性，不会出现特殊情况下奇怪的结果
- 近似LRU策略：采用时钟算法，系统中的所有页都放在一个循环列表中。每当页被引用时，硬件将使用位设置为1。当进行页替换时，如果页面P的使用位是1，则意味着页面P最近被使用，不适合被替换，然后，将P的使用位置为0；时钟指针递增到P+1页，该算法一直持续到找到一个使用位为0的页。时钟算法具有不重复扫描内存来寻找未使用页的特点
- 脏位：如果页已被修改，并因此变脏，则踢出它就必须将它写回磁盘，这很昂贵。因此，一些虚拟机系统更倾向于踢出干净页，而不是脏页
- 预取：对于大多数页而言，操作系统执行按需分页，在页被访问时将页载入内存中。当然，操作系统可能会猜测一个页面即将被使用，从而提前载入。这种行为被称为预取(prefetching)，只有在有合理的成功机会时才应该这样做
- 抖动：内存被超额请求，操作系统将不断地进行换页，这种现象被称为抖动
- 准入控制：给定一组进程，系统可以决定不运行部分进程，希望减少后的进程工作集（他们活跃使用的页面）能放入内存，从而能够取得进展。这表明，少做工作有时比尝试一下子做好所有事情更好
- 内存过载：当内存超额请求时，Linux会运行内存不足的杀手程序(out-of-memory killer)，这个守护进程选择一个内存密集型进程并杀死它
# 第23章 VAX/VMS虚拟内存系统
## 要点
- 通用性魔咒/分页和分段/在内核虚拟内存中放置用户页表
- 空指针访问/内核映射到每个地址空间
- 模拟引用位/分段FIFO/驻留集大小/二次机会列表
- 按需置零/写入时复制/惰性
## 知识点
- 通用性魔咒：操作系统常常有通用性魔咒问题，它们的任务是为广泛的应用程序和系统提供一般支持，其根本结果是操作系统不太可能很好地支持任何一个暗转。如何构建操作系统以便在各种系统上有效运行？
- 空指针访问：空指针访问会导致段错误，查询页表，会发现VPN 0的条目被标记为无效。因此，代码段永远不会从第0页开始。相反，该页被标记为不可访问，以便为检测空指针访问提供一些支持
- 内核映射到每个地址空间：内核虚拟地址空间（即其数据结构和代码）是每个用户地址空间的一部分。在上下文切换时，操作系统改变P0和P1寄存器以指向即将运行的进程的适当页表。但是，它不会更改S基址和界限寄存器，并因此将“相同的”内核结构映射到每个用户的地址空间
- 分段FIFO：为了应对自私贪婪的内存(memory hog)，即一些程序占用大量内存，使其它程序难以运行。在页替换策略中，LRU这种全局策略就会受到这种内存的影响，不会再进程之间公平分享内存。因此，踢出分段的FIFO替换策略，引入两个二次机会列表来解决该问题
- 按需置零：
  - 初级实现：在地址空间中添加页时，操作系统响应请求，在物理内存中找到页，将该页添加到你的堆中，并将其置零（否则，你可以看到其他进程使用该页时的内容），然后将其映射到你的地址空间（设置页表以根据需要引用该物理页），但初级实现可能是昂贵的，特别是如果页没有被进程使用
  - 按需置零：当页添加到你的地址空间时，操作系统会在页表中放入一个标记页不可访问的条目。如果进程读入或写入页，则会向操作系统发送陷阱。处理陷阱时，操作系统注意到这是一个按需置零页。此时，操作系统会完成寻找物理页的必要工作，将它置零，并映射到进程的地址空间。如果该进程从不访问该页，则所有这些工作都可以避免
- 写入时复制(copy-on-write):
  - 如果操作系统需要将一个页面从一个地址空间复制到另一个地址空间，不是实际复制它，而是将其映射到目标地址空间，并在两个地址空间中将其标记为只读。如果两个地址空间都只读取页面，则不会采取进一步的操作，因此操作系统实现了快速复制而不实际移动任何数据
  - 如果其中一个地址空间尝试写入页面，就会陷入操作系统，操作系统会注意到该页面是一个COW页面，因此（惰性地）分配一个新页，填充数据，并将这个新页映射到错误处理的地址空间。该进程然后继续，现在有了该页的私人副本
  - 任何类型的共享库都可以通过写时复制，映射到许多进程的地址空间中，从而节省宝贵的内存空间
  - UNIX系统中，fork()和exec()实现中，COW更加关键
- 惰性：惰性优化可以使得工作推迟，在操作系统中是有益大的。受限，推迟工作可能会减少当前操作的延迟，从而提高响应能力。其次，更重要的是，惰性有时会完全避免完成这项工作。例如，延迟写入直到文件被删除，根本不需要写入
# 第26章 并发：介绍
# 第27章 插叙：线程API
# 第28章 锁
# 第29章 基于锁的并发数据结构
# 第30章 条件变量
# 第31章 信号量
# 第32章 常见并发问题
# 第33章 基于事件的并发
# 第36章 I/O设备
# 第37章 磁盘驱动器
# 第38章 廉价冗余磁盘阵列（RAID）
# 第39章 插叙：文件和目录
# 第40章 文件系统实现
# 第41章 局部性和快速文件系统
# 第42章 崩溃一致性：FSCK和日志
# 第43章 日志结构文件系统
# 第44章 数据完整性和保护
# 第47章 分布式系统
# 第48章 Sun的网络文件系统（NFS）
# 第49章 Andrew文件系统（AFS）