# 第4章 抽象：进程
- 操作系统通过一些低级机制和高级策略来实现CPU虚拟化：让一个进程只运行一个时间片，然后切换到其它进程，来提供存在多个虚拟CPU的假象
- 机制为how问题提供答案，例如，操作系统如何执行上下文切换；策略为which问题提供答案，例如，操作系统现在应该运行哪个进程
- 进程包括机器状态（可以访问的内存、寄存器、持久存储设备）、进程状态（运行/就绪/阻塞/僵尸）等信息
- 操作系统将程序转化为进程，需要做以下几点
  - 将代码和所有静态数据（例如初始化变量）加载到内存中，加载到进程的地址空间中
  - 创建和初始化栈，为程序的运行时栈分配一些内存，存放局部变量、函数参数和返回地址
  - 为程序的堆分配一些内存，数据结构（如链表、散列表、树和其它有趣的数据结构）需要堆
  - 初始化I/O相关的任务，每个进程都有3个打开的文件描述符，用于标准输入、输出和错误
  - 启动程序，在入口处运行，即main()，OS将CPU的控制权转移到新创建的进程中，从而程序开始执行
# 第5章 插叙：进程API
- fork()和exec()组合在创建和操作进程时非常强大，shell本身，输出重定向和管道(使用pipe()系统调用)都是基于该组合实现的
- fork()和wait()组合，能让父进程等待子进程完成，使输出结果变得确定
# 第6章 机制：受限直接运行
- 虚拟化CPU时，希望在保留操作系统对CPU的控制权的同时，获得高性能，该技术称为受限（对应控制权）直接运行（对应高性能）
- 硬件通过提供用户模式、内核模式两种不同的执行模式来协助操作系统实现受限直接运行。用户程序一般运行在用户模式下，当希望执行某种特权操作时，硬件提供用户程序执行**系统调用**的能力，通过特殊的陷阱指令，跳入内核并将特权级别提升到内核模式来执行特权操作。完成后，操作系统调用从陷阱返回指令，回到发起调用的用户程序中，同时将特权级别降低，回到用户模式
- 在执行陷阱时，硬件需要确保存储足够的调用者寄存器，以便在操作系统发出从陷阱返回指令时能正确返回。在x86上，处理器会将程序计数器、标志和其他一些寄存器推送到每个进程的**内核栈**上。从陷阱返回时将从栈弹出这些值，并恢复执行用户模式程序
- 内核在启动时设置**陷阱表**，来告诉硬件在发生系统调用和其他异常事件时要运行哪些代码，指定要跳转到的地址
- 操作系统可通过等待系统调用、某种非法操作发生或者时钟中断来重新获得CPU的控制权。与系统调用类似，操作系统也必须通知硬件哪些代码在发生时钟中断时运行
- 操作系统在重新获得控制权后，可能会进行**上下文切换**，主要是切换内核栈，设计到两种类型的寄存器保存/恢复。第一种是发生时钟中断的时候，运行进程的用户寄存器由硬件隐式保存到该进程的内核栈；第二种是操作系统决定从A切换到B，内核寄存器被操作系统明确地保存到该进程的进程结构的内存中。目前个人理解是进程结构包括内核栈指针，可以从内核栈中恢复寄存器即进程上下文。操作系统通过切换进程结构来切换内核栈，进而在从陷阱返回时，从内核栈中恢复寄存器即切换进程上下文，从而实现进程切换。
- 现代处理器上，系统调用和上下文切换的性能可以达到亚微妙级，实现了高性能
- 受限直接访问背后的思想很简单：让程序运行的大部分指令直接访问硬件，只在一些关键点（如进程发生系统调用或发生时钟中断）由操作系统介入来确保“在正确的时间，正确的地点，做正确的事”。为了实现高效的虚拟化，操作系统应该尽量让程序自己运行，同时通过在关键点的及时介入，来保持对硬件的控制。高效和控制是现代操作系统的两个主要目标
# 第7章 进程调度：介绍
- 在不同工作负载假设时，会得到不同的最优调度策略。因此，确定工作负载是构建调度策略的关键部分。工作负载了解得越多，你的策略就越优化。最理想的负载假设包括
  - 每一个工作运行相同的时间
  - 所有的工作同时到达
  - 一旦开始，每个工作保持运行直到完成
  - 所有的工作只是用CPU（即他们不执行IO操作）
  - 每个工作的运行时间是已知的
- 通过调度指标来比较不同的调度策略，常用的调度指标包括周转时间和响应时间。周转时间反映性能；响应时间可以反映系统的交互性能，反映公平。性能和公平在调度系统中往往是矛盾的
- SJF/STCF优化周转时间，RR优化响应时间
- 摊销可以减少成本，重叠可以提供利用率
# 第8章 调度：多级反馈队列
- MLFQ中有许多独立的队列，每个队列有不同的优先级。MLFQ总是优先执行较高优先级的工作（即在较高级队列中的工作）；同一个队列中的工作采用轮转调度。因此，MLFQ调度策略的关键在于如何设置优先级
- MLFQ根据观察到的工作的行为调整它的优先级
- MLFQ的基本规则
  - 规则1：如果A的优先级 > B的优先级，运行A
  - 规则2：如果A的优先级 = B的优先级，轮转运行A和B
  - 规则3：工作进入系统时，放在最高优先级（最上层队列）
  - 规则4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）
  - 规则5：经过一段时间S，就将系统中所有工作重新加入最高优先级队列
# 第9章 调度：比例份额
- 比例份额是确保每个工作获得一定比例的CPU时间，而不是优化周转时间和响应时间
- 彩票调度最精彩的地方在于利用了随机性。当你需要做出决定时，采用随机的方式常常是既可靠又简单的选择
- 步长调度选择目前拥有最小行程值的进程，并且在运行之后将该进程的行程值增加一个步长
- 彩票调度算法只能运行一段时间后，在概率上实现比例，而步长调度算法可以在每个调度周期后做到完全正确
- 彩票调度算法相比步长调度算法，不需要全局状态，能够更合理地处理新加入的进程
# 第10章 多处理器调度
# 第13章 抽象：地址空间
- 一种实现时分共享的方法，是让一个进程单独占用全部内存运行一小段时间，然后停止它，并将它所有的状态信息保存在磁盘上
- 将全部的内存信息保存到磁盘太慢了，因此，在进程切换的时候，我们仍然将进程信息放在内存中。多个程序同时驻留在内存中，使保护成为重要问题
- 当我们描述地址空间时，所描述的是操作系统提供给运行程序的抽象。操作系统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转换为物理地址。作为用户级程序的程序员，可以看到的任何地址都是虚拟地址，只有操作系统和硬件才知道物理地址
# 第14章 插叙：内存操作API
- 程序运行时，会分配两种类型的内存：栈内存和堆内存
- malloc接受一个size_t类型参数，返回一个指向void类型的指针；free接受由malloc返回的指针，分配区域的大小不会被用户传入，必须由内存分配库本身记录追踪
# 第15章 机制：地址转换
- 为了高效、灵活地虚拟化内存，操作系统需要硬件的帮助，采用基于硬件的地址转换，一种典型的机制是基址加界限机制
- 为了支持基址加界限机制，对硬件和操作系统提出了很多要求
  - 硬件需要支持两种CPU模式：特权模式和用户模式。只要一个位，也许保存在处理器状态字中，就能说明当前CPU运行模式
  - 硬件需要提供基址和界限寄存器：硬件会转换每个地址，每个CPU需要一对寄存器来支持地址转换和界限检查
  - 硬件应该提供一些特殊指令，用于修改基址寄存器和界限寄存器：允许操作系统在切换进程时改变它们，这些指令是特权指令
  - 硬件应该提供注册异常处理程序的特权指令：操作系统必须能告诉硬件，如果异常发生，应该执行哪些代码
  - 硬件应该能够触发异常：如果进程试图使用特权指令或越界的内存
  - 操作系统在进程创建时，必须采取行动，为进程的地址空间找到内存空间
  - 操作系统在进程终止时（正常退出，或因行为不端被强制终止），必须做一些工作，回收它的所有内存，给其他进程或者操作系统使用
  - 操作系统在上下文切换时，也必须执行一些额外的操作，保存和恢复基址和界限寄存器。具体来说，当操作系统决定中止当前的运行进程时，它必须将当前基址和界限寄存器中的内容保存在内存中，放在某种每个进程都有的结构中，如进程结果或进程控制块中
  - 操作系统必须提供异常处理程序，当异常发生时执行该程序，可能的动作是中止犯错的进程
# 第16章 分段
- 基址和界限寄存器会造成内部碎片，造成内存浪费；通过分段，在MMU中为每个逻辑段引入一对基址和界限寄存器，可以支持稀疏地址空间
- 硬件通过虚拟地址可以知道地址引用了哪个段，以及段内的偏移量，从而正确进行地址转换
- 段寄存器需要包含基址、大小、是否正向增长、保护（共享代码段）
- 由于每个进程都有一些段，每个段的大小也可能不同，因此分段会造成外部碎片，通过紧凑物理内存或空闲列表管理算法，可以减少外部碎片
# 第17章 空闲空间管理
- 空闲空间管理的目标是碎片最小化，理想的内存分配程序可以同时保证快速和碎片最小化
- 内存分配程序通用机制包括：分割与合并；采用头块来追踪已分配空间的大小；在空闲区域的内部空间维护空闲列表，来追踪空闲和已分配的空间
- 空闲空间管理的基本策略包括最优匹配/最差匹配/首次匹配/下次匹配，其它的还包括分离空闲列表/伙伴系统/采用更复杂的数据结构而平衡二叉树来提升查找列表的速度/多核系统分配程序/glibc分配程序
# 第18章 分页：介绍
- 地址转换: 虚拟地址拆分为虚拟页号和页内的偏移量，用虚拟页号索引页表得到页表项进而得到物理帧号，物理帧号与偏移量组合即可得到真实地址
- 地址映射：由虚拟地址得到VPN和offset，由VPN和页表基址寄存器得到PTEAddr，访问页表项得到PFN，与offset组合得到PhysAddr，最后访问该物理地址。因此，对每个内存引用，分页都需要我们执行一个额外的内存引用，以便首先从页表中获得地址转换
# 第19章 分页：快速地址转换（TLB）
- 地址转换：在使用线性页表和TLB时，
- TLB的基本算法：
  - 首先从虚拟地址中提取页号(VPN)，然后检查TLB是否有该VPN的转换映射
  - 如果TLB命中，则从相关的TLB项中取出PFN，与虚拟地址中的偏移量组成期望的物理地址(PA)，并访问内存
  - 如果TLB未命中，则硬件访问页表来寻找转换映射，并用改转换映射更新TLB。当TLB更新成功后，系统会重新尝试原指令
- 上下文切换时对TLB的处理
  - TLB中包含的虚拟到物理的地址映射只对当前进程有效，对其它进程是没有意义的
  - 一种方式是简单地清空(flush)TLB，把全部有效位置零
  - 另一种方式是通过在TLB中添加地址空间标识符(ASID)，来实现跨上下文的TLB共享
# 第20章 分页：较小的表
- 分页和分段的基本算法：
  - 首先从虚拟地址中获得要引用的段，得到该段的页表的物理地址
  - 然后从虚拟地址中获得页表索引，得到页表项地址PTEAddr，进而得到物理地址的PFN，与offset结合，得到物理地址
- 多级页表的基本算法：
  - 首先从虚拟地址中获得页目录索引，结合页目录基址PDBR，得到页目录项的地址PDEAddr，查找到页表的物理地址PTEAddr
  - 然后从虚拟地址中获得页表索引，结合页表的物理地址PTEAddr，得到物理地址的PFN，与offset结合，得到物理地址
# 第21章 超越物理内存：机制
- 内存引用流程
  - 硬件首先从虚拟地址获得VPN，检查TLB是否匹配，如果命中，则获得最终的物理地址并从内存中返回
  - 如果TLB中找不到VPN即未命中，则硬件在内存中查找页表（使用页表基址寄存器），并使用VPN查找该页的页表项PTE，如果页有效且存在于物理内存中，则硬件从PTE中获得PFN，将其插入TLB，并重试该指令，这次产生TLB命中
  - 如果硬件在PTE中查找时，发现页不再物理内存中，即页未命中，则页错误处理程序运行，将需要的页从硬盘读取到内存，可能还需要先换出内存中的一些页，为即将换入的页腾出空y间
# 第22章 超越物理内存：策略
- 替换策略
  - 物理内存页可视为虚拟内存页的缓存，替换策略的目标是提高缓存命中率
  - 基本替换策略包括最优替换策略/FIFO/随机/LRU/近似LRU
  - 典型工作负载包括无局部性工作负载/80-20工作负载/循环工作负载
# 第23章 VAX/VMS虚拟内存系统
- 内存管理
  - VMS设计的首要目标是确保不会被页表占满内存。系统采用两种方式来减少页表对内存的压力
  - 采用分段和分页结合，栈和堆分别提供一个页表，栈和堆之间未使用的地址空间不需要页表
  - 在内核虚拟内存中放置用户页表（每个进程两个）
- 页替换
  - 模拟引用位：VMS使用保护位来模拟引用位，来确定哪些页时活跃的
  - 分段FIFO：在进程之间公平分享内存，每个进程可以保存在内存中的最大页数是有限制的
  - 页聚集：对页分组，执行更少和更大的写入，从而提高性能
- 惰性优化
  - 按需置零
  - 写时复制
# 第26章 并发：介绍
# 第27章 插叙：线程API
# 第28章 锁
# 第29章 基于锁的并发数据结构
# 第30章 条件变量
# 第31章 信号量
# 第32章 常见并发问题
# 第33章 基于事件的并发
# 第36章 I/O设备
# 第37章 磁盘驱动器
# 第38章 廉价冗余磁盘阵列（RAID）
# 第39章 插叙：文件和目录
# 第40章 文件系统实现
# 第41章 局部性和快速文件系统
# 第42章 崩溃一致性：FSCK和日志
# 第43章 日志结构文件系统
# 第44章 数据完整性和保护
# 第47章 分布式系统
# 第48章 Sun的网络文件系统（NFS）
# 第49章 Andrew文件系统（AFS）